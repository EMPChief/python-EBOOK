{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and importing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from platform import python_version\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/empchief/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'miracle_in_the_andes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as f:\n",
    "    book = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get number off chapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1\n",
      "\n",
      "Before\n",
      "\n",
      "\n",
      "IT WAS FRIDAY, the thirteenth of October. We joked about that—flying over the An\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(book[0:100])\n",
    "print(type(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "pattern = r'Chapter \\d+'\n",
    "chapters = re.findall(pattern, book)\n",
    "print(len(chapters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract some sentance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentence book got: 5347\n",
      "['Chapter 1\\n\\nBefore\\n\\n\\nIT WAS FRIDAY, the thirteenth of October.']\n"
     ]
    }
   ],
   "source": [
    "pattern2 = r'[a-zA-Z][^.!?]*[.!?]'\n",
    "sentences = re.findall(pattern2, book)\n",
    "count_sentences = len(sentences)\n",
    "print(f\"How many sentence book got: {count_sentences}\")\n",
    "print(sentences[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences with 'Andes' in them: 78\n",
      "['We joked about that—flying over the Andes on such an unlucky day, but young men make those kinds of jokes so easily.', 'Our pilots knew that this was the most dangerous time to fly across the Andes.', 'As we climbed, the plane banked steeply into a left turn and soon we were flying south, with the Argentine Andes rising to our right on the western horizon.', 'Uruguay is a low-lying country, and like most of my friends on the plane, my knowledge of the Andes, or of any mountains at all, was limited to what I had read in books.', 'In school we learned that the Andes range was the most extensive mountain system in the world, running the length of South America from Venezuela in the north to the southern tip of the continent in Tierra del Fuego.', 'I also knew that the Andes are the second-highest mountain range on the planet; in terms of average elevation, only the Himalayas are higher.', 'I had heard people refer to the Andes as one of the earth’s great geological wonders, and the view from the airplane gave me a visceral understanding of what that meant.', 'Our destination, Santiago, lies almost exactly due west of Mendoza, but the region of the Andes that separates the two cities is one of the highest sections of the entire chain, and home to some of the tallest mountains in the world.', 'We would fly south along the eastern foothills of the Andes with the mountains always on our right, until we reached the pass.', 'In the Southern Hemisphere, winter had given way to early spring, but in the Andes, temperatures still routinely dipped to 35 degrees below zero Fahrenheit, and the air was as dry as a desert.']\n"
     ]
    }
   ],
   "source": [
    "pattern3 = r'[a-zA-Z][^.!?]*Andes[^.!?]*[.!?]'\n",
    "sentences_with_andes = re.findall(pattern3, book)\n",
    "count_sentences_with_andes = len(sentences_with_andes)\n",
    "print(f\"How many sentences with 'Andes' in them: {count_sentences_with_andes}\")\n",
    "print(sentences_with_andes[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences with 'love' in them: 99\n",
      "Under the guidance of the Christian Brothers, both of us grew to love the game of rugby with a consuming passion.\n"
     ]
    }
   ],
   "source": [
    "word = 'love'\n",
    "pattern4 = rf'[a-zA-Z][^.!?]*{word}[^.!?]*[.!?]'\n",
    "\n",
    "sentences_with_love = re.findall(pattern4, book)\n",
    "count_sentences_with_love = len(sentences_with_love)\n",
    "\n",
    "print(f\"How many sentences with '{word}' in them: {count_sentences_with_love}\")\n",
    "print(sentences_with_love[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for most common word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(text, top_n):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    word_counts = Counter(words)\n",
    "    most_common = word_counts.most_common(top_n)\n",
    "    return most_common\n",
    "\n",
    "\n",
    "def find_top_words(text, top_count):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    word_counts = Counter(words)\n",
    "    most_common = word_counts.most_common(top_count)\n",
    "    return most_common\n",
    "\n",
    "\n",
    "def find_top_word_input(text, rank):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    word_counts = Counter(words)\n",
    "    most_common = word_counts.most_common()\n",
    "\n",
    "    if 1 <= rank <= len(most_common):\n",
    "        word, count = most_common[rank - 1]\n",
    "        print(f\"{rank}. '{word}' with {count} occurrences.\")\n",
    "    else:\n",
    "        print(\"Invalid rank input. Please enter a rank within the valid range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 'the' with 5346 occurrences.\n",
      "2. 'and' with 2795 occurrences.\n"
     ]
    }
   ],
   "source": [
    "top_n = 2\n",
    "result = most_common_words(book, top_n)\n",
    "for rank, (word, count) in enumerate(result, start=1):\n",
    "    print(f\"{rank}. '{word}' with {count} occurrences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 'the' with 5346 occurrences.\n",
      "2. 'and' with 2795 occurrences.\n"
     ]
    }
   ],
   "source": [
    "top_count_input = 2\n",
    "\n",
    "result = find_top_words(book, top_count_input)\n",
    "for rank, (word, count) in enumerate(result, start=1):\n",
    "    print(f\"{rank}. '{word}' with {count} occurrences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_input = int(input(\"Enter the rank of the word you want to see: \"))\n",
    "# find_top_word_input(book, rank_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_words(text):\n",
    "    pattern = re.compile(\"[a-zA-Z]+\")\n",
    "    findings = re.findall(pattern, text.lower())\n",
    "    return findings\n",
    "\n",
    "\n",
    "def count_word_occurrences(words):\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_words = find_words(book)\n",
    "word_occurrences = count_word_occurrences(found_words)\n",
    "\n",
    "d_list = [(value, key) for (key, value) in word_occurrences.items()]\n",
    "a_list = sorted(d_list, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2795, 'and'),\n",
       " (2729, 'i'),\n",
       " (2400, 'to'),\n",
       " (2060, 'of'),\n",
       " (1566, 'a'),\n",
       " (1430, 'was'),\n",
       " (1419, 'in'),\n",
       " (1226, 'we'),\n",
       " (1169, 'my')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most nonstop word used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common nonstop word is 'roberto' with 284 occurrences.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words = re.findall(r'\\b\\w+\\b', book.lower())\n",
    "nonstop_words = [word for word in words if word not in book]\n",
    "word_counts = Counter(nonstop_words)\n",
    "most_common_nonstop_word = word_counts.most_common(1)\n",
    "print(\n",
    "    f\"The most common nonstop word is '{most_common_nonstop_word[0][0]}' with {most_common_nonstop_word[0][1]} occurrences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chapter', 'before', 'it', 'was', 'friday']\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(\"[a-zA-Z]+\")\n",
    "findings = re.findall(pattern, book.lower())\n",
    "print(findings[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {}\n",
    "for word in findings:\n",
    "    if word in c.keys():\n",
    "        c[word] += 1\n",
    "    else:\n",
    "        c[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5346, 'the'), (2795, 'and'), (2729, 'i'), (2400, 'to'), (2060, 'of')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_list = [(value, key) for (key, value) in c.items()]\n",
    "c_sort = sorted(c_list, reverse=True)\n",
    "c_sort[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(575, 'would'),\n",
       " (519, 'us'),\n",
       " (292, 'said'),\n",
       " (284, 'roberto'),\n",
       " (252, 'could'),\n",
       " (249, 'one'),\n",
       " (227, 'snow'),\n",
       " (183, 'mountain'),\n",
       " (182, 'time'),\n",
       " (165, 'like')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list = []\n",
    "\n",
    "for count, word in c_list:\n",
    "    if word.lower() not in english_stopwords:\n",
    "        a_list.append((count, word))\n",
    "a_sort = sorted(a_list, reverse=True)\n",
    "a_sort[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to check if chapter is positive or negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_amplify_ep',\n",
       " '_amplify_qm',\n",
       " '_but_check',\n",
       " '_idioms_check',\n",
       " '_least_check',\n",
       " '_never_check',\n",
       " '_punctuation_emphasis',\n",
       " '_sift_sentiment_scores',\n",
       " 'constants',\n",
       " 'lexicon',\n",
       " 'lexicon_file',\n",
       " 'make_lex_dict',\n",
       " 'polarity_scores',\n",
       " 'score_valence',\n",
       " 'sentiment_valence']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.116, 'neu': 0.76, 'pos': 0.125, 'compound': 1.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.333, 'neu': 0.667, 'pos': 0.0, 'compound': -0.7177}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores = analyzer.polarity_scores(\n",
    "    \"There are too many horses out there, let's kill them all!\")\n",
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'compound': 0.6989}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(\n",
    "    \"I really love them all!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a posteritive book\n",
      "The book has 0.125 positive score and 0.116 negative score | 0.76 neutral score!\n"
     ]
    }
   ],
   "source": [
    "scores = analyzer.polarity_scores(book)\n",
    "\n",
    "if scores[\"pos\"] > scores[\"neg\"]:\n",
    "    print(\"This is a posteritive book\")\n",
    "    print(\n",
    "        f\"The book has {scores['pos']} positive score and {scores['neg']} negative score | {scores['neu']} neutral score!\")\n",
    "elif scores[\"pos\"] < scores[\"neg\"]:\n",
    "    print(\"This is a negative book\")\n",
    "    print(\n",
    "        f\"The book has {scores['pos']} positive score and {scores['neg']} negative score | {scores['neu']} neutral score!\")\n",
    "else:\n",
    "    print(\"This is a neutral book\")\n",
    "    print(\n",
    "        f\"The book has {scores['pos']} positive score and {scores['neg']} negative score | {scores['neu']} neutral score!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze by chapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern5 = re.compile(\"Chapter [0-9]+\")\n",
    "chapter_split = re.split(pattern5, book)\n",
    "chapter_split = chapter_split[1:]\n",
    "chapter_titles = re.findall(pattern5, book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1 Scores: 0.16 positive score! | 0.061 negative score! | 0.779 neutral score! | 1.0\n",
      "Positive\n",
      "Chapter 2 Scores: 0.154 positive score! | 0.12 negative score! | 0.726 neutral score! | 0.9991\n",
      "Positive\n",
      "Chapter 3 Scores: 0.105 positive score! | 0.145 negative score! | 0.751 neutral score! | -0.9999\n",
      "Negative\n",
      "Chapter 4 Scores: 0.138 positive score! | 0.141 negative score! | 0.721 neutral score! | -0.9963\n",
      "Negative\n",
      "Chapter 5 Scores: 0.141 positive score! | 0.118 negative score! | 0.742 neutral score! | 0.9997\n",
      "Positive\n",
      "Chapter 6 Scores: 0.115 positive score! | 0.124 negative score! | 0.761 neutral score! | -0.9979\n",
      "Negative\n",
      "Chapter 7 Scores: 0.103 positive score! | 0.136 negative score! | 0.761 neutral score! | -0.9999\n",
      "Negative\n",
      "Chapter 8 Scores: 0.094 positive score! | 0.12 negative score! | 0.786 neutral score! | -0.9998\n",
      "Negative\n",
      "Chapter 9 Scores: 0.079 positive score! | 0.097 negative score! | 0.824 neutral score! | -0.9996\n",
      "Negative\n",
      "Chapter 10 Scores: 0.181 positive score! | 0.086 negative score! | 0.733 neutral score! | 1.0\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "for i, chapter_split in enumerate(chapter_split):\n",
    "    chapter_title = chapter_titles[i]\n",
    "    scores = analyzer.polarity_scores(chapter_split)\n",
    "    print(\n",
    "        f\"{chapter_title} Scores: {scores['pos']} positive score! | {scores['neg']} negative score! | {scores['neu']} neutral score! | {scores['compound']}\")\n",
    "    if scores[\"pos\"] > scores[\"neg\"]:\n",
    "        print(\"Positive\")\n",
    "    elif scores[\"pos\"] < scores[\"neg\"]:\n",
    "        print(\"Negative\")\n",
    "    else:\n",
    "        print(\"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
